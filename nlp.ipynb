{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# I recommend you leave this on True when grading, it disables the \n",
        "# back-translation data augmentation and does a single training loop \n",
        "# instead of a hyper-parameter search.\n",
        "\n",
        "# Feel free to switch it to False to test all the features but be warned that\n",
        "# execution can take upwards of two hours.\n",
        "\n",
        "# Also don't forget to upload all the CSV files included in the repo to \n",
        "# your Colab environment!\n",
        "\n",
        "is_grader = True"
      ],
      "metadata": {
        "id": "0n5NDaLgBl7F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RaumtTUK2wf"
      },
      "source": [
        "# Installs & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmXKsT8qtA4v",
        "outputId": "3103df20-cb90-4c50-8a73-3d39766a2b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.18.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (1.10.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: pickle5==0.0.10 in /usr/local/lib/python3.7/dist-packages (0.0.10)\n",
            "Requirement already satisfied: nlpaug in /usr/local/lib/python3.7/dist-packages (1.1.10)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.1.4)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.44.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (21.4.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.3)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (1.2.13)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.13.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt) (2.6.3)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece transformers datasets numpy pandas ray[tune] hyperopt ray pickle5==0.0.10 nlpaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtmFS_P8rkGC",
        "outputId": "1d4657e8-2daa-4740-e3a4-6f613791b3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import ray\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import nlpaug\n",
        "import nlpaug.augmenter.word as naw\n",
        "from datasets import load_dataset, load_metric, Dataset, DatasetDict, load_from_disk\n",
        "from transformers import (AutoModelForSequenceClassification, AutoTokenizer,\n",
        "                          Trainer, TrainingArguments, EarlyStoppingCallback, set_seed)\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from ray import tune\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDdwLYIoK-97"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yZQKPfF7s5oX"
      },
      "outputs": [],
      "source": [
        "# Grab these three files from the repo and upload them to your Colab session\n",
        "\n",
        "train_ids = set(pd.read_csv('train_ids.csv').par_id.values)\n",
        "val_ids = set(pd.read_csv('dev_ids.csv').par_id.values)\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('dontpatronizeme_pcl.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"] = df.text.apply(str)\n",
        "\n",
        "# Remove stopwords from the text and compute number of words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def f(x):\n",
        "    words = word_tokenize(x)\n",
        "    final_tokens = []\n",
        "    for each in words:\n",
        "        if each not in stop_words:\n",
        "            final_tokens.append(each)\n",
        "    return len(final_tokens)\n",
        "\n",
        "df[\"input_len\"] = df.text.apply(f)\n",
        "\n",
        "# Generate plot for label counts\n",
        "label_counts = df.label.value_counts().to_numpy()\n",
        "\n",
        "x = list(range(5))\n",
        "y = label_counts\n",
        "\n",
        "x_pos = [i for i, _ in enumerate(x)]\n",
        "\n",
        "plt.bar(x_pos, y, color='blue')\n",
        "plt.xlabel(\"Label Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Input Count Per Label Type\")\n",
        "\n",
        "plt.xticks(x_pos, x)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Generate plot for input length\n",
        "input_lengths = df.groupby('label')['input_len'].mean()\n",
        "\n",
        "y = input_lengths\n",
        "\n",
        "plt.bar(x_pos, y, color='blue')\n",
        "plt.xlabel(\"Label Type\")\n",
        "plt.ylabel(\"Number of Words (Excluding Stop Words)\")\n",
        "plt.title(\"Input Length Per Label Type\")\n",
        "\n",
        "plt.xticks(x_pos, x)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "haTMS_iUESyG",
        "outputId": "c2f9b216-3c8f-4fb6-dd9c-e9e68b747188"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing & Augmentation"
      ],
      "metadata": {
        "id": "rDIONgWSIGiH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7eMPYXa8s5oX"
      },
      "outputs": [],
      "source": [
        "# Load a fresh copy of the dataset\n",
        "df = pd.read_csv('dontpatronizeme_pcl.tsv', sep='\\t')\n",
        "\n",
        "# Make sure there is text\n",
        "df = df[df['text'].notna()]\n",
        "# Bin the labels\n",
        "df[\"labels\"] = df.label.apply(lambda x: 0 if x == 0 or x == 1 else 1)\n",
        "\n",
        "# Clean-up the text by removing text that brings no meaningful information\n",
        "df[\"text\"] = df.text.apply(lambda t: t.replace(\"<h>\", \"\"))\n",
        "remove = [\"-- AFP\", \"/AFP /\", \"/AFP\", \"PHOTO AFP\", \"/ AFP PHOTO /\", \n",
        "          \"AFP PHOTO\", \"( AFP )\", \"-AFP\", \"PHOTO : AFP\", \"AFP/\", \"( Photo : AFP/SAM YEH )\", \"AFP Photo\", \n",
        "          \"PHOTO SIA KAMBOU AFP  In Summary\", \"PHOTO : China Daily/Asia News Network\", \n",
        "          \"( SUPPLIED PHOTO )\", \"PHOTO ABDIMALIK HAJIR NATION MEDIA GROUP  In Summary\", \n",
        "          \"PHOTO : REUTERS .\", \"- PHOTO BY CARL GILCHRIST\", \"PHOTO : SUPPLIED\",\n",
        "          \"PHOTO : CHOO CHWEE HUA\", \"PHOTO : astrid februarie\",\n",
        "          \"XINHUA PHOTO - ZHAI JIANLAN\", \"PHOTO : REUTERS\", \"Photograph : Alkis Konstantinidis/Reuters\",\n",
        "          \"Photograph : Darko Vojinovic/AP\", \"( Photo : Ron Batzdorff/NBC/NBCU Photo Bank via Getty Images )\", \n",
        "          \"Image : AP Photo\", \"Photo : AP/Matt Dunham\", \"Photo : Prabir Das\", \n",
        "          \"Photo : Getty Images\", \"( Photo : News18 )\", \"( AP Photo/Emilio Morenatti )\", \n",
        "          \"( AP Photo/Claudia Torrens )\", 'Photo : mostafigur rahman', \n",
        "          \"( AP Photo/Matt Dunham )\", \"Photograph : Hassan Ammar/AP\", \"( AP )\", \n",
        "          \"( Photo : Omar Fungo )\", \"( AP Photo/MANILA BULLETIN )\", \"Photo- Creative Commons\",\n",
        "          \"Photo : AP\", \"( AP Photo/Jerome Delay , File/ MANILA BULLETIN )\",\n",
        "          \"( Photo : Getty )\", \"File photograph : iStockPhoto\", \"( Photos : SOSD )\",\n",
        "          \"( AP Photo/Min Kyi Thein )\", \"Photo/Sportpicha  In Summary\", \"Photo:Frank Aman\",\n",
        "          \"AP Photo/Themba Hadebe\", \"Photo/un.org\", \"( AP Photo/Firdia Lisnawati/ MANILA BULLETIN )\",\n",
        "          \"( File Photo/REUTERS )\", \"( AP Photo/Mosa'ab Elshamy )\", \" ( Photo : Khalfan Said )\",\n",
        "          \"( Photo by Peti Siyame )\", \"Photo : Boipelo Mere\", \"Photo : STARHossain Seraj , Magura\",\n",
        "          \"( AP Photo/Kathy Willens , File ) Comments\", \"Photo : asif mahmud ove\", \"( Photos by Staff Photographer )\",\n",
        "          \"( Photo : SAM YEH )\", \"( Photo : Alan Chin for Yahoo News )\", \"( Photo by Selin Thomas )\", \"Source : AAP\",\n",
        "          \"( Source : YouTube ) \"]\n",
        "for r in remove:\n",
        "  df[\"text\"] = df.text.apply(lambda t: t.replace(r, \"\"))\n",
        "\n",
        "df[\"text\"] = df.text.apply(lambda t: t.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O_blduF7s5oZ"
      },
      "outputs": [],
      "source": [
        "# Split dataset into train, val and test\n",
        "df_train = df[df.par_id.isin(train_ids)][[\"text\", \"labels\"]]\n",
        "df_val = df[df.par_id.isin(val_ids)][[\"text\", \"labels\"]]\n",
        "df_test = pd.read_csv('test_set.tsv', sep='\\t')[[\"text\"]]\n",
        "\n",
        "\n",
        "# Contextual word embedding augmentation. This will insert new words into the\n",
        "# samples by feeding the surrounding words into BERT and inserting the word that\n",
        "# is closest to the surrounding words in BERT's latent space.\n",
        "aug1 = naw.ContextualWordEmbsAug(\n",
        "    model_path='bert-base-uncased', action=\"insert\", device=\"cuda\")\n",
        "aug2 = naw.SynonymAug(aug_src='wordnet')\n",
        "\n",
        "if not is_grader:\n",
        "  aug3 = naw.BackTranslationAug(device=\"cuda\")\n",
        "  aug4 = naw.RandomWordAug(action=\"swap\")\n",
        "\n",
        "augs = []\n",
        "augs += list(df_train[df_train.labels==1].text.apply(lambda t: aug1.augment(t, n=2)))\n",
        "augs += list(df_train[df_train.labels==1].text.apply(lambda t: aug2.augment(t, n=2)))\n",
        "\n",
        "# The back-translation augmentation can take upwards of \n",
        "# an hour to run, even on a P100 GPU\n",
        "if not is_grader:\n",
        "  augs += list(df_train[df_train.labels==1].text.apply(lambda t: aug3.augment(t, n=2)))\n",
        "  augs += list(df_train[df_train.labels==1].text.apply(lambda t: aug4.augment(t, n=2)))\n",
        "\n",
        "df_train_augmented = df_train.append([{\"text\": aug, \"labels\": 1} for aug in augs])\n",
        "df_train_augmented = df_train_augmented.explode(\"text\")\n",
        "\n",
        "# We can skip this data checkpoint when grading\n",
        "if not is_grader:\n",
        "  df_train.to_csv(\"df_train.csv\")\n",
        "  df_train_augmented.to_csv(\"df_train_augmented.csv\")\n",
        "\n",
        "if is_grader:\n",
        "  N = 3900\n",
        "else:\n",
        "  N = 7000\n",
        "  \n",
        "# Construct a perfectly balanced dataset by sampling from the negative samples\n",
        "# and the positive samples (augmented)\n",
        "df_train_augmented = pd.concat([df_train_augmented[df_train_augmented.labels==0].sample(N), \n",
        "                                df_train_augmented[df_train_augmented.labels==1].sample(N)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_BgE1m_Xug5c"
      },
      "outputs": [],
      "source": [
        "def generate_tokenized_data(model_name, train, val, test):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=128)\n",
        "\n",
        "  def tokenize_function(sample):\n",
        "      return tokenizer(sample[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "  train_data = Dataset.from_pandas(train[[\"text\", \"labels\"]], preserve_index=False)\n",
        "  val_data = Dataset.from_pandas(val[[\"text\", \"labels\"]], preserve_index=False)\n",
        "  test_data = Dataset.from_pandas(test[[\"text\"]], preserve_index=False)\n",
        "\n",
        "  dd = DatasetDict({\"train\": train_data, \"val\": val_data, \"test\": test_data})\n",
        "\n",
        "  dd = dd.map(tokenize_function, batched=True)\n",
        "\n",
        "  return dd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "zWht6Xv-INeS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TNYiJd88r4j7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ded851312647401cb0cc197872aec4b5",
            "8e7aacb02dda4b5faec15582f6efb9e9",
            "da8e359fe98040b2b6d7289df3eed8ed",
            "159ab4831bd44acb81ec96b8d0785a20",
            "7dd262008c1748c4a7e74d4ec46b1f6d",
            "796840acaa5a44678eac0b6c9ff83e21",
            "658081249ca74c80b3864d571db35ada",
            "47e7b248b0a04815aaf33e963646be61",
            "e89897fe4a8a4ea2ad355821223478d5",
            "34da57214b384af9ba6e2fe10dc04bbc",
            "d064d0240281430d9f3b4cbd0030903a",
            "e9f186eff0b64c2c8522084a368ee3c9",
            "3d3d30460522406f80a43c87cdc70f60",
            "9511f75acaa54112a3004d81e0a6b336",
            "aff71da7a65845f795c970729361cc14",
            "ac7ae85b04b64e8aaea534cf62418a44",
            "a58ef40b21ae4758b8b58da77068401a",
            "d061bcb13b3b4cce8b2e63d4098c21b1",
            "85e3ad3655ec472188d264778f969108",
            "962806f3659b44d2a153e47cb02d7832",
            "fb9eb58947124cf8b9196d8a82eee8e7",
            "6ca61debd212464eaa3c1e6daebd70d1",
            "08d7bb3937744005a7e47c861236ae0c",
            "4b91097494d04338a49710c90bf64756",
            "f2e6b99c292a44038b1c89525538c293",
            "fe07a53473fa4ac0a58d107d1e1eb254",
            "f08045e12aee4ac8ad8af219024d1efb",
            "d101999231e24fedbb307c1af46e8db7",
            "ddec19bae6424821be755cbaa0c36ba3",
            "ee866c55e5224b3ab678b89f4f5b9490",
            "5e06515c8d614c9eaf73baaca23c5683",
            "325918a5606e4da0ba1d83c52f344fe4",
            "800dfb2916004207b2d0a8790473d894"
          ]
        },
        "outputId": "5177696c-dbc5-48a3-83a8-0d8102d2c4d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ded851312647401cb0cc197872aec4b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9f186eff0b64c2c8522084a368ee3c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08d7bb3937744005a7e47c861236ae0c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"roberta-base\"\n",
        "\n",
        "dd = generate_tokenized_data(model_name, df_train_augmented, df_val, df_test)\n",
        "\n",
        "\n",
        "set_seed(38)\n",
        "early_stopping_patience = 5\n",
        "\n",
        "def get_model():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\n",
        "            model_name,\n",
        "            num_labels=2\n",
        "        )\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "        output_dir=\".\",\n",
        "        learning_rate=2e-5,  # overriden by hparam search\n",
        "        do_train=True,\n",
        "        do_eval=True,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        save_strategy=\"steps\",\n",
        "        eval_steps=50,\n",
        "        save_steps=50,\n",
        "        num_train_epochs=10,  # early stopping\n",
        "        save_total_limit=early_stopping_patience,\n",
        "        load_best_model_at_end=True,\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=32,\n",
        "        gradient_accumulation_steps=1,\n",
        "        metric_for_best_model = 'f1',\n",
        "        warmup_steps=385,  # overriden by hparam search\n",
        "        weight_decay=0.3,  # overriden by hparam search\n",
        "        logging_dir=\"./logs\",\n",
        "        skip_memory_metrics=True,\n",
        "        report_to=\"none\")\n",
        "\n",
        "metric = load_metric(\"f1\")\n",
        "def compute_metrics(eval_pred):\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "trainer = Trainer(\n",
        "        model_init=get_model,\n",
        "        args=training_args,\n",
        "        train_dataset=dd[\"train\"],\n",
        "        eval_dataset=dd[\"val\"],\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks = [EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oO_vRgDR4sDL",
        "outputId": "24f7515c-3e9f-42da-86fb-25f30c5f91be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 7800\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2440\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1450' max='2440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1450/2440 16:29 < 11:16, 1.46 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.728824</td>\n",
              "      <td>0.173647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.348282</td>\n",
              "      <td>0.025751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.288231</td>\n",
              "      <td>0.367688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.271347</td>\n",
              "      <td>0.518349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.242382</td>\n",
              "      <td>0.457143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.220164</td>\n",
              "      <td>0.392283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.251415</td>\n",
              "      <td>0.539615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.282248</td>\n",
              "      <td>0.519231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.254903</td>\n",
              "      <td>0.486486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.283131</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.208480</td>\n",
              "      <td>0.504792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.229229</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.256399</td>\n",
              "      <td>0.549738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.220776</td>\n",
              "      <td>0.562814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.260417</td>\n",
              "      <td>0.536023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.394489</td>\n",
              "      <td>0.556364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.357157</td>\n",
              "      <td>0.577963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.289977</td>\n",
              "      <td>0.491909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.316070</td>\n",
              "      <td>0.545906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.374523</td>\n",
              "      <td>0.473684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.541710</td>\n",
              "      <td>0.549098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.412779</td>\n",
              "      <td>0.579075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.522359</td>\n",
              "      <td>0.557522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.469991</td>\n",
              "      <td>0.599057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.407150</td>\n",
              "      <td>0.512195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.508450</td>\n",
              "      <td>0.584112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.497120</td>\n",
              "      <td>0.507463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.441516</td>\n",
              "      <td>0.555858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.099800</td>\n",
              "      <td>0.470797</td>\n",
              "      <td>0.538012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-50\n",
            "Configuration saved in ./checkpoint-50/config.json\n",
            "Deleting older checkpoint [checkpoint-200] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-400] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-600] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-800] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-1000] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-1200] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-1400] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-100] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-150] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-250] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-300] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-350] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-450] due to args.save_total_limit\n",
            "Deleting older checkpoint [checkpoint-500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-100\n",
            "Configuration saved in ./checkpoint-100/config.json\n",
            "Deleting older checkpoint [checkpoint-550] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-150\n",
            "Configuration saved in ./checkpoint-150/config.json\n",
            "Deleting older checkpoint [checkpoint-50] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-200\n",
            "Configuration saved in ./checkpoint-200/config.json\n",
            "Deleting older checkpoint [checkpoint-650] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-250\n",
            "Configuration saved in ./checkpoint-250/config.json\n",
            "Deleting older checkpoint [checkpoint-700] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-300\n",
            "Configuration saved in ./checkpoint-300/config.json\n",
            "Deleting older checkpoint [checkpoint-750] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-350\n",
            "Configuration saved in ./checkpoint-350/config.json\n",
            "Deleting older checkpoint [checkpoint-100] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-400\n",
            "Configuration saved in ./checkpoint-400/config.json\n",
            "Deleting older checkpoint [checkpoint-150] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-450\n",
            "Configuration saved in ./checkpoint-450/config.json\n",
            "Deleting older checkpoint [checkpoint-200] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-500\n",
            "Configuration saved in ./checkpoint-500/config.json\n",
            "Deleting older checkpoint [checkpoint-250] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-550\n",
            "Configuration saved in ./checkpoint-550/config.json\n",
            "Deleting older checkpoint [checkpoint-300] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-600\n",
            "Configuration saved in ./checkpoint-600/config.json\n",
            "Deleting older checkpoint [checkpoint-350] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-650\n",
            "Configuration saved in ./checkpoint-650/config.json\n",
            "Deleting older checkpoint [checkpoint-400] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-700\n",
            "Configuration saved in ./checkpoint-700/config.json\n",
            "Deleting older checkpoint [checkpoint-450] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-750\n",
            "Configuration saved in ./checkpoint-750/config.json\n",
            "Deleting older checkpoint [checkpoint-500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-800\n",
            "Configuration saved in ./checkpoint-800/config.json\n",
            "Deleting older checkpoint [checkpoint-550] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-850\n",
            "Configuration saved in ./checkpoint-850/config.json\n",
            "Deleting older checkpoint [checkpoint-600] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-900\n",
            "Configuration saved in ./checkpoint-900/config.json\n",
            "Deleting older checkpoint [checkpoint-650] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-950\n",
            "Configuration saved in ./checkpoint-950/config.json\n",
            "Deleting older checkpoint [checkpoint-700] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-1000\n",
            "Configuration saved in ./checkpoint-1000/config.json\n",
            "Deleting older checkpoint [checkpoint-750] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-1050\n",
            "Configuration saved in ./checkpoint-1050/config.json\n",
            "Deleting older checkpoint [checkpoint-800] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-1100\n",
            "Configuration saved in ./checkpoint-1100/config.json\n",
            "Deleting older checkpoint [checkpoint-850] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-1150\n",
            "Configuration saved in ./checkpoint-1150/config.json\n",
            "Deleting older checkpoint [checkpoint-900] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-1200\n",
            "Configuration saved in ./checkpoint-1200/config.json\n",
            "Deleting older checkpoint [checkpoint-950] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-1250\n",
            "Configuration saved in ./checkpoint-1250/config.json\n",
            "Deleting older checkpoint [checkpoint-1000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-1300\n",
            "Configuration saved in ./checkpoint-1300/config.json\n",
            "Deleting older checkpoint [checkpoint-1050] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-1350\n",
            "Configuration saved in ./checkpoint-1350/config.json\n",
            "Deleting older checkpoint [checkpoint-1100] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-1400\n",
            "Configuration saved in ./checkpoint-1400/config.json\n",
            "Deleting older checkpoint [checkpoint-1150] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2093\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to ./checkpoint-1450\n",
            "Configuration saved in ./checkpoint-1450/config.json\n",
            "Deleting older checkpoint [checkpoint-1250] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./checkpoint-1200 (score: 0.5990566037735848).\n"
          ]
        }
      ],
      "source": [
        "if is_grader:\n",
        "  trainer.train()\n",
        "else:\n",
        "  # Initialise ray for hyper-param search\n",
        "  ray.shutdown()\n",
        "  ray.init(log_to_driver=True, ignore_reinit_error=True)\n",
        "\n",
        "  scheduler = tune.schedulers.PopulationBasedTraining(\n",
        "      mode = \"max\",\n",
        "      metric='eval_f1',\n",
        "      perturbation_interval=2,\n",
        "      hyperparam_mutations={\n",
        "          \"weight_decay\": tune.uniform(0.0, 0.3),\n",
        "          \"learning_rate\": tune.uniform(1e-5, 5e-5),\n",
        "          \"warmup_steps\": tune.randint(0, 500)\n",
        "      }\n",
        "  )\n",
        "\n",
        "  best_trial = trainer.hyperparameter_search(\n",
        "      direction=\"maximize\",\n",
        "      backend=\"ray\",\n",
        "      n_trials=10,\n",
        "      keep_checkpoints_num=1,\n",
        "      scheduler=scheduler)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "nlp.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2ea756720fbc36d1db084f042c9e216a5d04841d2942bfb875ad835fd0c58808"
    },
    "kernelspec": {
      "display_name": "Python 3.9.9 ('nlp-cw-VaOvvE7p-py3.9')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ded851312647401cb0cc197872aec4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e7aacb02dda4b5faec15582f6efb9e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_da8e359fe98040b2b6d7289df3eed8ed",
              "IPY_MODEL_159ab4831bd44acb81ec96b8d0785a20",
              "IPY_MODEL_7dd262008c1748c4a7e74d4ec46b1f6d"
            ]
          }
        },
        "8e7aacb02dda4b5faec15582f6efb9e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da8e359fe98040b2b6d7289df3eed8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_796840acaa5a44678eac0b6c9ff83e21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_658081249ca74c80b3864d571db35ada"
          }
        },
        "159ab4831bd44acb81ec96b8d0785a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_47e7b248b0a04815aaf33e963646be61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 8,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e89897fe4a8a4ea2ad355821223478d5"
          }
        },
        "7dd262008c1748c4a7e74d4ec46b1f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_34da57214b384af9ba6e2fe10dc04bbc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/8 [00:00&lt;00:00,  9.59ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d064d0240281430d9f3b4cbd0030903a"
          }
        },
        "796840acaa5a44678eac0b6c9ff83e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "658081249ca74c80b3864d571db35ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47e7b248b0a04815aaf33e963646be61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e89897fe4a8a4ea2ad355821223478d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34da57214b384af9ba6e2fe10dc04bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d064d0240281430d9f3b4cbd0030903a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9f186eff0b64c2c8522084a368ee3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d3d30460522406f80a43c87cdc70f60",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9511f75acaa54112a3004d81e0a6b336",
              "IPY_MODEL_aff71da7a65845f795c970729361cc14",
              "IPY_MODEL_ac7ae85b04b64e8aaea534cf62418a44"
            ]
          }
        },
        "3d3d30460522406f80a43c87cdc70f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9511f75acaa54112a3004d81e0a6b336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a58ef40b21ae4758b8b58da77068401a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d061bcb13b3b4cce8b2e63d4098c21b1"
          }
        },
        "aff71da7a65845f795c970729361cc14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85e3ad3655ec472188d264778f969108",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_962806f3659b44d2a153e47cb02d7832"
          }
        },
        "ac7ae85b04b64e8aaea534cf62418a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb9eb58947124cf8b9196d8a82eee8e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 13.87ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ca61debd212464eaa3c1e6daebd70d1"
          }
        },
        "a58ef40b21ae4758b8b58da77068401a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d061bcb13b3b4cce8b2e63d4098c21b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85e3ad3655ec472188d264778f969108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "962806f3659b44d2a153e47cb02d7832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb9eb58947124cf8b9196d8a82eee8e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ca61debd212464eaa3c1e6daebd70d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08d7bb3937744005a7e47c861236ae0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4b91097494d04338a49710c90bf64756",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2e6b99c292a44038b1c89525538c293",
              "IPY_MODEL_fe07a53473fa4ac0a58d107d1e1eb254",
              "IPY_MODEL_f08045e12aee4ac8ad8af219024d1efb"
            ]
          }
        },
        "4b91097494d04338a49710c90bf64756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2e6b99c292a44038b1c89525538c293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d101999231e24fedbb307c1af46e8db7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddec19bae6424821be755cbaa0c36ba3"
          }
        },
        "fe07a53473fa4ac0a58d107d1e1eb254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee866c55e5224b3ab678b89f4f5b9490",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e06515c8d614c9eaf73baaca23c5683"
          }
        },
        "f08045e12aee4ac8ad8af219024d1efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_325918a5606e4da0ba1d83c52f344fe4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00,  9.00ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_800dfb2916004207b2d0a8790473d894"
          }
        },
        "d101999231e24fedbb307c1af46e8db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddec19bae6424821be755cbaa0c36ba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee866c55e5224b3ab678b89f4f5b9490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e06515c8d614c9eaf73baaca23c5683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "325918a5606e4da0ba1d83c52f344fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "800dfb2916004207b2d0a8790473d894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}